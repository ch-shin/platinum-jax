{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c18a6f-feac-4c30-9e76-096fba8cbbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 09:14:19.640799: W external/xla/xla/service/gpu/nvptx_compiler.cc:744] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "# https://roberttlange.com/posts/2020/03/blog-post-10/\n",
    "\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "\n",
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80412f-d743-4697-9573-f4a4e50e5ac3",
   "metadata": {},
   "source": [
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2f1381-fd7a-4711-8cb8-75c425533034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.9 ms, sys: 1.78 ms, total: 64.7 ms\n",
      "Wall time: 7.31 ms\n",
      "CPU times: user 172 ms, sys: 476 ms, total: 648 ms\n",
      "Wall time: 41.2 ms\n",
      "CPU times: user 790 µs, sys: 1.33 ms, total: 2.12 ms\n",
      "Wall time: 139 µs\n"
     ]
    }
   ],
   "source": [
    "# Generate a random matrix\n",
    "x = random.uniform(key, (1000, 1000))\n",
    "# Compare running times of 3 different matrix multiplications\n",
    "%time y = onp.dot(x, x)\n",
    "%time y = np.dot(x, x)\n",
    "%time y = np.dot(x, x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6637e-20e4-4d01-bbb3-b7a3b786d1c6",
   "metadata": {},
   "source": [
    "# jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d660be8-db85-4ec7-ac08-74ac29aad8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    \"\"\" Rectified Linear Unit (ReLU) activation function \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "jit_ReLU = jit(ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db4fb7b-96e3-428e-a7dd-c17b86c6d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 6.27 ms, total: 25.8 ms\n",
      "Wall time: 31.6 ms\n",
      "CPU times: user 9.58 ms, sys: 2.46 ms, total: 12 ms\n",
      "Wall time: 18.9 ms\n",
      "CPU times: user 111 µs, sys: 0 ns, total: 111 µs\n",
      "Wall time: 175 µs\n"
     ]
    }
   ],
   "source": [
    "%time out = ReLU(x).block_until_ready()\n",
    "# Call jitted version to compile for evaluation time!\n",
    "%time jit_ReLU(x).block_until_ready()\n",
    "%time out = jit_ReLU(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f244acb-4c9b-47e7-9052-9bc268b01e8f",
   "metadata": {},
   "source": [
    "# grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933a0ae9-a50a-4dbf-9146-9d33aea7fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax Grad:  1.0\n",
      "FD Gradient: 0.99998707\n"
     ]
    }
   ],
   "source": [
    "def FiniteDiffGrad(x):\n",
    "    \"\"\" Compute the finite difference derivative approx for the ReLU\"\"\"\n",
    "    return np.array((ReLU(x + 1e-3) - ReLU(x - 1e-3)) / (2 * 1e-3))\n",
    "\n",
    "# Compare the Jax gradient with a finite difference approximation\n",
    "print(\"Jax Grad: \", jit(grad(jit(ReLU)))(2.))\n",
    "print(\"FD Gradient:\", FiniteDiffGrad(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f602acd-63b0-4236-9580-8a7f47550976",
   "metadata": {},
   "source": [
    "# vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "981842f5-5316-47ec-83bb-8c854d410b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 3.01 ms, total: 16.6 ms\n",
      "Wall time: 11.5 ms\n",
      "CPU times: user 230 µs, sys: 174 µs, total: 404 µs\n",
      "Wall time: 297 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[ 0.49068165,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.7020273 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.8156922 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  7.3970523 ],\n",
       "       ...,\n",
       "       [ 6.127812  ,  0.        ,  0.        , ...,  6.7456055 ,\n",
       "         0.        , 11.019837  ],\n",
       "       [ 0.        ,  0.        , 21.238281  , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  6.715443  ,  0.        , ...,  0.        ,\n",
       "         0.        , 10.9453125 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dim = 32\n",
    "feature_dim = 100\n",
    "hidden_dim = 512\n",
    "\n",
    "# Generate a batch of vectors to process\n",
    "X = random.normal(key, (batch_dim, feature_dim))\n",
    "\n",
    "# Generate Gaussian weights and biases\n",
    "params = [random.normal(key, (hidden_dim, feature_dim)),\n",
    "          random.normal(key, (hidden_dim, ))]\n",
    "\n",
    "def relu_layer(params, x):\n",
    "    \"\"\" Simple ReLu layer for single sample \"\"\"\n",
    "    return ReLU(np.dot(params[0], x) + params[1])\n",
    "\n",
    "def batch_version_relu_layer(params, x):\n",
    "    \"\"\" Error prone batch version \"\"\"\n",
    "    return ReLU(np.dot(X, params[0].T) + params[1])\n",
    "\n",
    "def vmap_relu_layer(params, x):\n",
    "    \"\"\" vmap version of the ReLU layer \"\"\"\n",
    "    return jit(vmap(relu_layer, in_axes=(None, 0), out_axes=0))\n",
    "\n",
    "%time ut = np.stack([relu_layer(params, X[i, :]) for i in range(X.shape[0])])\n",
    "%time out = batch_version_relu_layer(params, X)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7182f5bf-764b-4bf3-a11d-3c0e47438338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78 µs, sys: 58 µs, total: 136 µs\n",
      "Wall time: 141 µs\n",
      "[[ 0.49068165  0.          0.         ...  0.          0.\n",
      "   0.7020273 ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.8156922 ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   7.3970523 ]\n",
      " ...\n",
      " [ 6.127812    0.          0.         ...  6.7456055   0.\n",
      "  11.019837  ]\n",
      " [ 0.          0.         21.238281   ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          6.715443    0.         ...  0.          0.\n",
      "  10.9453125 ]]\n"
     ]
    }
   ],
   "source": [
    "%time out = vmap_relu_layer(params, X)\n",
    "print(out(params, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed724b1a-bad0-4181-aae0-4b6cfc894f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 12. 12. 12. 12.]\n",
      " [12. 12. 12. 12. 12.]]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "A, B, C, D = 2, 3, 4, 5\n",
    "x = jnp.ones((A, B))\n",
    "y = jnp.ones((B, C))\n",
    "z = jnp.ones((C, D))\n",
    "def foo(tree_arg):\n",
    "  x, (y, z) = tree_arg\n",
    "  return jnp.dot(x, jnp.dot(y, z))\n",
    "tree = (x, (y, z))\n",
    "print(foo(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8d50841-63be-4b2f-8244-ff788fa7263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "from jax import vmap\n",
    "K = 6  # batch size\n",
    "x = jnp.ones((K, A, B))  # batch axis in different locations\n",
    "y = jnp.ones((B, K, C))\n",
    "z = jnp.ones((C, D, K))\n",
    "tree = (x, (y, z))\n",
    "vfoo = vmap(foo, in_axes=((0, (1, 2)),))\n",
    "print(vfoo(tree).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platinum-jax",
   "language": "python",
   "name": "platinum-jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
